{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8ZCvkGNzYhoK/xS6LzN5Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryan-saloma/bike-market-summit/blob/main/Bike_Market_Summit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J27nsnPRNHD3"
      },
      "outputs": [],
      "source": [
        "%pip install -U googlemaps\n",
        "\n",
        "import googlemaps as gm\n",
        "import requests\n",
        "import pandas as pd\n",
        "import plotly\n",
        "import plotly.express as px\n",
        "\n",
        "gmaps = gm.Client(key='XXXXXXXXXX')\n",
        "\n",
        "# First get location of Summit, NJ\n",
        "def get_coordinates_from_address(address, api_key):\n",
        "    url = 'https://maps.googleapis.com/maps/api/geocode/json'\n",
        "    params = {\n",
        "        'address': address,\n",
        "        'key': api_key\n",
        "    }\n",
        "    response = requests.get(url, params=params)\n",
        "    if response.status_code == 200:\n",
        "        results = response.json().get('results')\n",
        "        if results:\n",
        "            location = results[0]['geometry']['location']\n",
        "            return location['lat'], location['lng']\n",
        "        else:\n",
        "            print(\"No results found for the given city name.\")\n",
        "            return None\n",
        "    else:\n",
        "        print(f\"Error: {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "summit_trek_coords = \\\n",
        "get_coordinates_from_address('348 Springfield Ave, Summit, NJ 07901', gmaps.key)\n",
        "\n",
        "# How far would someone travel for a bike?\n",
        "# According to a bike forum, some people are willing to drive 2+ hours\n",
        "# source: https://www.bikeforums.net/road-cycling/947577-how-far-you-willing-drive-buy-new-bike.html\n",
        "#\n",
        "# According to one study, people typically don't travel more than 20 min\n",
        "# for routine purchases. This suggests the market for bikes and the market for\n",
        "# bike accessories are different, as people will travel further for expensive\n",
        "# purchases and unique experiences (classes, etc.)\n",
        "#\n",
        "# source: https://blog.accessdevelopment.com/research-how-far-will-consumers-travel-to-make-routine-purchases\n",
        "#\n",
        "# TODO: work the other direction and figure out how large an area you'd need to\n",
        "# reach to meet sales goals\n",
        "\n",
        "bike_stores = gmaps.places(query='bike store', \\\n",
        "                                 location=summit_trek_coords,radius=10000, \\\n",
        "                                 type='bicycle_store')\n",
        "# Get results as a list of dicts\n",
        "results = bike_stores['results']\n",
        "\n",
        "# Perform list comprehension to extract keys of interest\n",
        "keys_of_interest = ['name', 'rating', 'user_ratings_total', 'geometry']\n",
        "stores_df = pd.DataFrame(results)\n",
        "stores_df\n",
        "\n",
        "# Get coords of competing stores\n",
        "coords_competition = pd.DataFrame()\n",
        "coords_competition['Name'] = stores_df['name']\n",
        "coords_competition['Latitude'] = stores_df['geometry'].apply(lambda x: x['location']['lat'])\n",
        "coords_competition['Longitude'] = stores_df['geometry'].apply(lambda x: x['location']['lng'])\n",
        "coords_competition['Rating'] = stores_df['rating']\n",
        "coords_competition['Number of Ratings'] = stores_df['user_ratings_total']\n",
        "coords_competition\n",
        "\n",
        "coords_competition.dropna(\n",
        "    axis=0,\n",
        "    how='any',\n",
        "    subset=None,\n",
        "    inplace=True\n",
        ")\n",
        "\n",
        "color_scale = [(0, 'orange'), (1,'red')]\n",
        "\n",
        "fig = px.scatter_mapbox(coords_competition,\n",
        "                        lat=\"Latitude\",\n",
        "                        lon=\"Longitude\",\n",
        "                        hover_name=\"Name\",\n",
        "                        hover_data=[\"Name\", \"Rating\"],\n",
        "                        color=\"Rating\",\n",
        "                        color_continuous_scale=color_scale,\n",
        "                        size=\"Number of Ratings\",\n",
        "                        zoom=8,\n",
        "                        height=800,\n",
        "                        width=800)\n",
        "\n",
        "fig.update_layout(mapbox_style=\"open-street-map\")\n",
        "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
        "fig.show()\n",
        "plotly.io.write_html(fig, \"competition_map.html\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Market Analysis\n",
        "\n",
        "Sources:\n",
        "- https://www.businessnewsdaily.com/15751-conduct-market-analysis.html\n",
        "- https://www.sba.gov/business-guide/plan-your-business/market-research-competitive-analysis\n",
        "\n",
        "Who are my potential customers?\n",
        "What are my customers' buying habits?\n",
        "How large is my target market?\n",
        "How much are customers willing to pay for my product?\n",
        "Who are my main competitors?\n",
        "What are my competitors' strengths and weaknesses?\n",
        "\n",
        "To-Do List\n",
        "- List products sold at Trek Store, list products made by Trek, disjoint set\n",
        "- Get reviews from competitors, create word cloud"
      ],
      "metadata": {
        "id": "V_F_EuAIOoGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Product Information\n",
        "\n",
        "%mkdir scraper\n",
        "%pip install bs4\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Set base URL\n",
        "base_url = \"https://www.trekbikes.com/us/en_US/retail/summit/\"\n",
        "headers = requests.utils.default_headers()\n",
        "headers.update({\n",
        "    'User-Agent': 'Mozilla/5.0',\n",
        "})\n",
        "proxies = {\n",
        "    'http':'XXXXXXXXXXXXXXX'\n",
        "}\n",
        "\n",
        "#\n",
        "k = requests.get(base_url, headers=headers, proxies=proxies).text\n",
        "soup = BeautifulSoup(k,'html.parser')\n",
        "product_list = soup.find_all(\"div\", {\"class\": \"cat-product-thumb-container\"})\n",
        "product_list\n",
        "\n",
        "# It looks like the content might be dynamically loaded, given the results\n",
        "# We need to use Selenium instead"
      ],
      "metadata": {
        "id": "_E7dtyYiQiA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install selenium\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.headless = True\n",
        "driver = webdriver.Chrome(chrome_options)\n",
        "driver.get('https://www.trekbikes.com/us/en_US/bikes/c/B100/')\n",
        "all_links = []\n",
        "\n",
        "def extract_links_from_page(driver):\n",
        "    # Extract all the links on the current page\n",
        "    links = driver.find_elements(By.TAG_NAME, 'a')\n",
        "    return [link.get_attribute('href') for link in links if link.get_attribute('href')]\n",
        "\n",
        "while True:\n",
        "    # Extract links from the current page\n",
        "    all_links.extend(extract_links_from_page(driver))\n",
        "\n",
        "    # Check if there's a \"Next\" button to go to the next page\n",
        "    try:\n",
        "        next_button = driver.find_element(By.ID, 'search-page-next')  # Adjust this locator as needed\n",
        "        if next_button.get_attribute('class') != 'pagination__button arrow-right-icon--weak disabled':\n",
        "            next_button.click()\n",
        "        else:\n",
        "            break\n",
        "    except:\n",
        "        break\n",
        "\n",
        "unique_links = set(all_links)\n",
        "links_series = pd.Series(list(unique_links))\n",
        "links_series.to_csv('links_to_bikes.csv')"
      ],
      "metadata": {
        "id": "0FpNhimMk5vo"
      },
      "execution_count": 56,
      "outputs": []
    }
  ]
}